
# Tokenize
* For each target file in parallel:
	* Run the DFAs for each type of token on the file's contents (DFAs generated by a python script)
	* Watch which DFAs accept, and add those maximal-munched tokens to the stream.
	* If invalid input is found (ex: input file contains unprintable characters that cannot be matched by any token rule),
	  return an error instead of the token stream.
	* Repeat until the whole file is processed
* If there are tokenizer errors, print and exit the program.
* Return all the token steams

# Parse
* For each token stream in parallel:
	* Create an Arena to allocate nodes and associated information on.
	* Call the initial parsing rule, parse_CompilationUnit().
		* This calls other recursively decendng rules in sequence.
		* Each parsing rule carefully manages the parser's state.
			* Each parsing rule pushes itself onto the parser's "call stack" (a stack of rule names being parsed,
			  which is the recursive state of the parser), and pops when finished. This is useful for debugging.
			* Fragments are parsing rules which should not create an AST in the finished product, and therefore
			  must be freed immediately. They are useful, for example, for parsing argument lists.
			* It's very important that a failed parsing rule does not cause a memory leak. Most parsing rules do
			  fail in this way, so the memory usage would quickly grow out of control.
			* When a parsing a fragment, the caller should clean up.
		* If in a compilation unit a parse is requred to succeed and fails (syntax error), capture the state of the
		  parser, the position in the token stream, return an error, and exit the thread. This way, each compilation
		  unit can report up to one syntax error, and it's deterministic which one is found and the order they are
		  reported.

# Validate AST
### Pass one:
For each compilation unit in parallel:
	* Sort the compilation unit's children into their type (Functions, Classes, Traits, Global variables, etc).
	* Combine String literals. Ex: "Hello " "World" "!"
	* Validate that float and integer literals can fit.
	* Pull out all the trait, function, class, and type names from the root of each. Keep track of how far nested you 
	  found them.


# Semantic/Type Analysis

# Trait Monomorphization

# Static Analysis
* Validate that duplicate typedefs don't define the type differently, then replace with the real type.
* Build a hierarchy of types.
    * Circular and multiple template implements are okay, but make sure they're handled.
* Infer Generics, keeping a note. Native methods cannot accept or return generics, but can be in a generic class.
* Traverse the AST, starting from the bottom.
    * Validate types and combine values known at compile time.
    * Apply widening conversions automatically. Disallow narrowing conversions without a cast.
        * Integer types can cast to float types, except ULong to Float, because it is narrowing.
    * Infer the return values of functions by their signature (mindful that overloads exist).
* Validate Interfaces are implemented and types match

# Code Generator
Information that must be known:
Function Signatures
Which generic overloads are used


* Write all type declarations
* Write all function declarations

* Write all struct definitions
* Write all function definitions


