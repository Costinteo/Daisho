// THIS FILE GENERATED BY GenTokType.py. DO NOT EDIT.
#ifndef INCLUDE_TOKENS
#define INCLUDE_TOKENS
#include <apaz-libc.h>

#define NUM_TOKTYPES 83
enum TokType {
  WS,
  IMPORT,
  SL_COMMENT,
  ML_COMMENT,
  IDENT,
  TRAIT,
  END_OF_FILE,
  INVALID,
  NATIVE,
  CTYPE,
  BOOL,
  CHAR,
  UCHAR,
  SHORT,
  USHORT,
  INT,
  UINT,
  LONG,
  FLOAT,
  DOUBLE,
  VOID,
  IF,
  ELSE,
  FOR,
  WHILE,
  CONTINUE,
  BREAK,
  IN,
  CLASS,
  THIS,
  OPERATOR,
  IMPL,
  ENUM,
  PRIVATE,
  PROTECTED,
  PUBLIC,
  INSTANCEOF,
  SIZEOF,
  ASSERT,
  TRUE,
  FALSE,
  LPAREN,
  RPAREN,
  LBRACE,
  RBRACE,
  LBRACK,
  RBRACK,
  LARROW,
  RARROW,
  SEMI,
  COMMA,
  DOT,
  STAR,
  EQUALS,
  LAMBDA_ARROW,
  BANG,
  TILDE,
  QUESTION,
  COLON,
  EQUAL,
  LE,
  GE,
  NOTEQUAL,
  AND,
  OR,
  INC,
  DEC,
  ADD,
  SUB,
  DIV,
  AMP,
  BITOR,
  CARET,
  MOD,
  DEREF_ARROW,
  ADD_ASSIGN,
  SUB_ASSIGN,
  MUL_ASSIGN,
  DIV_ASSIGN,
  AND_ASSIGN,
  OR_ASSIGN,
  XOR_ASSIGN,
  MOD_ASSIGN,
};
typedef enum TokType TokType;
static const char* TokNameMap[] = {
  "['NATIVE', 'native']", 
  "['CTYPE', 'ctype']", 
  "['BOOL', 'Bool']", 
  "['CHAR', 'Char']", 
  "['UCHAR', 'UChar']", 
  "['SHORT', 'Short']", 
  "['USHORT', 'UShort']", 
  "['INT', 'Int']", 
  "['UINT', 'UInt']", 
  "['LONG', 'Long']", 
  "['FLOAT', 'Float']", 
  "['DOUBLE', 'Double']", 
  "['VOID', 'Void']", 
  "['IF', 'if']", 
  "['ELSE', 'else']", 
  "['FOR', 'for']", 
  "['WHILE', 'while']", 
  "['CONTINUE', 'continue']", 
  "['BREAK', 'break']", 
  "['IN', 'in']", 
  "['CLASS', 'class']", 
  "['THIS', 'this']", 
  "['OPERATOR', 'operator']", 
  "['IMPL', 'impl']", 
  "['ENUM', 'enum']", 
  "['PRIVATE', 'private']", 
  "['PROTECTED', 'protected']", 
  "['PUBLIC', 'public']", 
  "['INSTANCEOF', 'instanceof']", 
  "['SIZEOF', 'sizeof']", 
  "['ASSERT', 'assert']", 
  "['TRUE', 'true']", 
  "['FALSE', 'false']", 
  "['LPAREN', '(']", 
  "['RPAREN', ')']", 
  "['LBRACE', '{']", 
  "['RBRACE', '}']", 
  "['LBRACK', '[']", 
  "['RBRACK', ']']", 
  "['LARROW', '<']", 
  "['RARROW', '>']", 
  "['SEMI', ';']", 
  "['COMMA', ',']", 
  "['DOT', '.']", 
  "['STAR', '*']", 
  "['EQUALS', '=']", 
  "['LAMBDA_ARROW', '=>']", 
  "['BANG', '!']", 
  "['TILDE', '~']", 
  "['QUESTION', '?']", 
  "['COLON', ':']", 
  "['EQUAL', '==']", 
  "['LE', '<=']", 
  "['GE', '>=']", 
  "['NOTEQUAL', '!=']", 
  "['AND', '&&']", 
  "['OR', '||']", 
  "['INC', '++']", 
  "['DEC', '--']", 
  "['ADD', '+']", 
  "['SUB', '-']", 
  "['DIV', '/']", 
  "['AMP', '&']", 
  "['BITOR', '|']", 
  "['CARET', '^']", 
  "['MOD', '%']", 
  "['DEREF_ARROW', '->']", 
  "['ADD_ASSIGN', '+=']", 
  "['SUB_ASSIGN', '-=']", 
  "['MUL_ASSIGN', '*=']", 
  "['DIV_ASSIGN', '/=']", 
  "['AND_ASSIGN', '&=']", 
  "['OR_ASSIGN', '|=']", 
  "['XOR_ASSIGN', '^=']", 
  "['MOD_ASSIGN', '%=']", 
  "WS", 
  "IMPORT", 
  "SL_COMMENT", 
  "ML_COMMENT", 
  "IDENT", 
  "TRAIT", 
  "END_OF_FILE", 
  "INVALID"
};


#endif // INCLUDE_TOKENS